---
title: Bias A.I. Can Evaluate Humans through Facial Recognition:<br>Implications of Using Artificial Intelligence
  in the Federal Law Enforcement
author: "Jim H. Ong <br> United States Secret Service"
output:
  html_document: default
---
M.A. Candidate, Johns Hopkins University, 2019 <br>
B.A., University of California, Los Angeles, 2015 <br>
Data used in the [original article](JournalofManagement) can be found in [Harvard.dataverse.edu](www.harvard.dataverse.edu)<br>
<br>
This study was created during my training period at the United States Secret Service, and it is a part of my Capstone Project at the Johns Hopkins University. I am writing this tutorial for two purposes. First, I hope that my writing will serve as a resource to anyone interested in artificial intelligence, machine learning, and natural language processing. To be specific, I am creating this tutorial with likeminded beginners in mind. So, if you're a seasoned computer programmer, you may find some information here unnecessarily lengthy. Nevertheless, speaking as a person who's not attained a formal degree in computer programming, I learned to code by reading and following along tutorials written by others, and so this is the best way I can share and transfer my knowledge back to the community that has been so generous and thoughtful in my askings during challenges - I hope it will be useful. That said, I would like to thank the members of [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/) team, of Stanford University, and [Semantics derived automatically from language corpora contain human-like biases](http://science.sciencemag.org/content/356/6334/183) team, of Princeton University and the University of Bath, for sharing their code. It was very helpful replicating the methodologies.

Second, this tutorial serves to show how we created our experiment. Anyone who may be interested in our study is welcome to replicate our method because we are sharing 100% of our computer scripts as well as cited sources. However, much of our work is an extension of existing studies and replicated materials, so I do not claim sole credit for the computer scripts that are written here. This is an evolving knowledge of humankind, and I view my work as the sum of all efforts, so what you find here to the extent of what I have contributed belongs to the public.

Finally, I would like to thank my mentors for supporting me with this project. It is a great honor to place my name alongside yours' as the lead researcher in publications.

Let's get started, shall we?<br><br>


```{r setup, include=FALSE}
library(cbn)
cbn_set_vectorfile_location("/Users/dell/Google Drive/Documents/Coding/R-AI/glove.840B.300d.txt", persist = TRUE)

```

## Understanding CBN

In this section, we examine the instructional codes provided by the authors of _Semantics derived automatically from language corpora contain human-like biases_ (from hereon referred to it as _Caliskan study_). Most codes you see under this section originates from the authors I am replicating (most - because some inherent programming functions like `paste0` are embedded as a part of the author's code), and I'm simply repeating what was used by the researchers and sharing my interpretation of what they were doing. But first things first, you have to satisfy two things before moving onto the next steps:
<br><br>
1) Get familiar with GloVe. Replicating the [Stanford GloVe study](https://nlp.stanford.edu/projects/glove/) is not necessary for this tutorial, but skim through and experiment with it to familiarize yourself with the concept. Unless files have been deleted, you should be able to download pre-trained corpus data that was used in the original research. Additionally, perhaps more important to your replication efforts, the authors have shared their machine learning code.
<br><br>
2) Install the cbn package. Normally, I would say type `install.packages("cbn")` on your console, but the chances are that this will not work. That is because as I am typing this at the moment, the **cbn** package is not available in CRAN or other repositories I've checked. I am going to write a guide on how to manually install packages separately [here](). Once you have successfully installed __cbn__, run this:
<br><br>
```{r eval = FALSE}
library(cbn)
```
<br>
The pre-trained GloVe vectors come with the cbn package, so you won't need to run the below code from your end. However, we removed every pre-installed vector data before installing the cbn package, then created our own vectors using the original pre-trained GloVe data. We did this to see if there would be any difference between the output results generated by pre-installed data and the manually loaded pre-trained GloVe data. You can delete the preinstalled data by removing all of the files located inside the `.../cbn/data/` folder.

Anyway, skip the below part and move onto the next one. This is just to show you the additional step we took from our end.
<br><br>
``` {r eval = FALSE}
cbn_set_vectorfile_location("parent directory goes here/glove.840B.300d.txt", persist = TRUE)
```
<br>
Skip above, then run this code:
<br><br>
# eval = FALSE until reinstall ready
``` {r eval = FALSE}
its <- cbn_get_items("WEAT", 1)
summary(its)
```
<br>
The output shows that there are 25 words for each of the conditions. Recall back in the Caliskan study that the researchers were investigating whether machines can process biased linguistic information and exhibit signs of stereotype similar to the human bias measured in the implicit association test (IAT).

Caliskan et. al. used the same target concepts used in the IAT mdoel: Flowers and Insects. These are the words they used for the target and attribute.
<br><br>
```{r eval= FALSE}
Flowers <- c("aster", "clover", "hyacinth", "marigold", "poppy", "azalea",
                  "crocus", "iris", "orchid", "rose", "bluebell", "daffodil",
                  "lilac", "pansy", "tulip", "buttercup", "daisy", "lily",
                  "peony", "violet", "carnation", "gladiola", "magnolia",
                  "petunia", "zinnia")
Insects <- c("ant", "caterpillar", "flea", "locust", "spider", "bedbug",
                  "centipede", "fly", "maggot", "tarantula", "bee", "cockroach",
                  "gnat", "mosquito", "termite", "beetle", "cricket", "hornet",
                  "moth", "wasp", "blackfly", "dragonfly", "horsefly", "roach",
                  "weevil")
Pleasant <- c("caress", "freedom", "health", "love", "peace", "cheer",
                   "friend", "heaven", "loyal", "pleasure", "diamond", "gentle",
                   "honest", "lucky", "rainbow", "diploma", "gift", "honor",
                   "miracle", "sunrise", "family", "happy", "laughter",
                   "paradise", "vacation")
Unpleasant <- c("abuse", "crash", "filth", "murder", "sickness",
                     "accident", "death", "grief", "poison", "stink", "assault",
                     "disaster", "hatred", "pollute", "tragedy", "divorce",
                     "jail", "poverty", "ugly", "cancer", "kill", "rotten",
                     "vomit", "agony", "prison")
```
<br>

Let's take a look at the results.
<br><br>
# eval = FALSE until reinstall ready
``` {r eval = FALSE}
vecs <- cbn_get_item_vectors("WEAT", 1)
weat_perm(its, vecs, x_name = "Flowers", y_name = "Insects",
          a_name = "Pleasant", b_name = "Unpleasant", 1000)

#     S_xyab        d p_value
# 1 2.238165 1.504315       0
```
<br>
Congratulations, you've successfully replicated one part of WEAT experiments. In their publication, Caliskan et. al. reported that two sets of 25 target words and 25 attribute words produced a Cohen's _d_ of 1.50 with a _p_-value of 10^-7.

Recall that we removed pre-installed vector data before installing the cbn package, then installed pre-trained GloVe data ourselves. After removing the unlikelihood of data alteration, we were able to replicate the authors' results. This strengthens the validity of Caliskan study. Therefore, we confidently confirm producing identical statistical results using the author's method.

Now, because scientists are skeptics by profession, we are breaking down the authors' script to pieces from the beginning (And, mostly for the sake of my erudition).
<br><br>
``` {r eval = FALSE}
its <- cbn_get_items("WEAT", 1)
```
<br>
This is saying that everything on the right side of the equation is being stored as _its_. But, what does it exactly mean by `cbn_get_items("WEAT", 1)`? According to the cbn package documentation, `cbn_get_items` "returns a data frame containing the items from one of the studies (WEAT1 through WEAT10 or WEFAT1 or WEFAT2) or a vector containing all items from all studies if type == "all"." Hmmmmmkay, cool. I'm going to digest that concept by typing `View(cbn_get_items)`, which returns the following:
<br><br>
``` {r eval=FALSE}
View(cbn_get_items)

function (type = c("all", "WEAT", "WEFAT"), number = 1) 
{
  study_type <- match.arg(type)
  if (study_type == "all") {
    its <- unique(cbn::cbn_items$Word)
  }
  else {
    sname <- paste0(study_type, number)
    its <- cbn::cbn_items[cbn::cbn_items$Study == sname, 
      ]
    class(its) <- c("cbn_study", class(its))
  }
  its
}
```
<br>
I don't know about nerds because I'm not one of them, but this function is a geek satisfactor - a clean and simple function that works and is easy to understand. And yes, there is a difference between nerds and geeks. Geeks are obviously the awesome pawsome ones. You're welcome.

Anyway, when users punch in the type of study (all, WEAT, WEFAT), either one of two tautology follows: _if_ condition or _else_ condition. If users type _all_ (that is, `cbn_get_items(all)`), then the function grabs every word in the `cbn_items` located inside the cbn package. In other way of looking at it, imagine a master spreadsheet named *cbn_items* and that this spreadsheet contains every word used in the Caliskan study. Its columns include study types by study number (i.e. WEAT1, WEAT2, WEFAT2, etc.), words (i.e., female, male, butterfly, bee, etc.), and associated roles (target or attribute). `cbn_get_items` is grabbing everything in the Word column from that spreadsheet. Why? I don't know yet.

In the other case, the _else_ condition, there are two parts of interest: _sname_ and _its_. For the _sname_, we see that the condition assignment is `paste0(study_type, number)`. When we typed  `cbn_get_items("WEAT", 1)`, _WEAT_ and _1_ were separated by a comma. However, looking at the `View(cbn_items)`, study types are stored as one word (i.e., WEAT1, WEAT2, WEAT3 ...). It appears that the author is using the `paste0` function to concatenate _WEAT_ and _1_ in order to combine the separated values to one word before loading only the specified study type (WEAT1) from the _master spreadsheet_.

Next, digest `vecs <- cbn_get_item_vectors("WEAT", 1)` by typing `View(cbn_get_item_vectors)`. Here is the returned output.
<br><br>
``` {r eval = FALSE}
function (type = c("all", "WEAT", "WEFAT"), number = 1) 
{
  study_type <- match.arg(type)
  if (study_type == "all") {
    vecs <- cbn::cbn_item_vectors
  }
  else {
    its <- cbn_get_items(type = type, number = number)
    vecs <- cbn::cbn_item_vectors[its$Word, ]
  }
  vecs
}

```







## Lazy Method

Don't need or don't want explanations? Cool beans. Here is the full code:


